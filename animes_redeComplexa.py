# -*- coding: utf-8 -*-
"""ProjetoPratico_RodrigoBrochardt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jFYqpRgFTR2NhrVTO4k99K9yReS4SzDW
"""

from google.colab import drive
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive
import pandas as pd
from matplotlib.pyplot import figure


drive.mount('/content/drive')

"""# Importar arquivo do banco de dados Anime"""

df = pd.read_csv('/content/drive/MyDrive/animes.csv')

df.loc[df['uid'] == 1333] #hub do grafo

"""# Eliminar duplicidade de registro"""

df = df[['uid','genre']]
df = df.drop_duplicates()

"""# Manipular banco de dados para criar conexões"""

data = {'id' :[], 'target': []}
range = 0
for i in df.values:
  range += 1
  for j in df[range:].values:
    genre_first = eval(i[1])
    genre_second = eval(j[1])
    if (len(genre_first) > 0 and len(genre_second) > 0):
      similaridade = len(set(genre_first) & set(genre_second)) / float(len(set(genre_first) | set(genre_second))) * 100
      if(similaridade > 70):
        data['id'].append(i[0])
        data['target'].append(j[0])

"""# Gerar novo DataFrame com os nós e enlaces"""

G = pd.DataFrame (data, columns = ['id','target'])
Graph = nx.from_pandas_edgelist(G,source='id',target='target')
componentes = sorted(nx.connected_components(Graph), key=len, reverse=True)
maior_componente = Graph.subgraph(componentes[0])

"""# Obter informações do grafo gerado

Número de nós:
"""

numero_nos = maior_componente.number_of_nodes()
print('Número de nós: ' + str(numero_nos))

"""Número de enlaces:"""

numero_enlaces = maior_componente.number_of_edges()
print('Número de enlaces: ' + str(numero_enlaces))

"""Sequência do grau"""

deg_maior_componente = [d for n,d in nx.degree(maior_componente)]
lista_com_ids = [n for n,d in nx.degree(maior_componente)]

"""Grau médio:"""

grau_medio = np.average([d for n,d in nx.degree(maior_componente)])
print('Grau médio: ' + str(grau_medio))

"""Porcentagem dos nós menores que o grau médio( P(di < λ) ):"""

quantidade_nos_menor = 0
for i in deg_maior_componente:
  if i < grau_medio:
    quantidade_nos_menor += 1

porcentagem_menor = (quantidade_nos_menor * 100)/numero_nos
print("Porcentagem dos nós menores que o grau médio: " + str(porcentagem_menor))

"""Grau do hub:"""

hub = np.max(deg_maior_componente)
print("Hub: " + str(hub))

deg_maior_componente.index(343) #obter indice do maior hub
print("Id do hub: " + str(lista_com_ids[1167])) #obter o anime que possui maior grau

"""Tamanho médio dos caminhos:"""

tmc =nx.average_shortest_path_length(maior_componente)
print("TMC: " + str(tmc))

"""Diâmetro do grafo:"""

diametro = nx.diameter(maior_componente)
print("Diâmetro do grafo: " + str(diametro))

"""Coeficiênte de Aglomeração:"""

CC =nx.average_clustering(maior_componente)
print("CC: " + str(CC))

"""Densidade do grafo:"""

densidade = nx.density(maior_componente)
print("Densidade: " + str(densidade))

"""Eficiência dos enlaces"""

Ef = 1 - tmc/numero_enlaces
print("Eficiência dos enlaces: "+str(Ef))

"""Histograma"""

deg_Graph = [d for n,d in nx.degree(maior_componente)]

#Frequência do grau 
h = [ i/Graph.number_of_nodes() for i in nx.degree_histogram(maior_componente) ]
print("H = " + str(h))

#Entropia 
I = - np.nansum(h*np.log2(h))
print("Entropia = " + str(I))

#Histograma
plt.hist(deg_maior_componente, weights= np.ones_like(deg_maior_componente) / len(deg_maior_componente))
plt.title('Histograma')
plt.xlabel('Grau')
plt.ylabel('Probabilidade')
plt.show()